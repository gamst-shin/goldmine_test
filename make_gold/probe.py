import os
import sys
import time
import random
import re
import django
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager

# =========================================================
# 1. Django í™˜ê²½ ì„¤ì • (DB ì ‘ì†ìš©)
# =========================================================
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.append(project_root)

os.environ.setdefault("DJANGO_SETTINGS_MODULE", "config.settings")
django.setup()

from make_gold.models import AuctionItem

# =========================================================
# 2. ë„ìš°ë¯¸ í•¨ìˆ˜ë“¤ (ë°ì´í„° ì •ì œ)
# =========================================================
def extract_weight(text):
    """ 
    'ì´ ì¤‘ëŸ‰ : 3.75g' ê°™ì€ í…ìŠ¤íŠ¸ì—ì„œ ìˆ«ì(3.75)ë§Œ floatë¡œ ì¶”ì¶œ 
    """
    try:
        # ìˆ«ì + (ì  + ìˆ«ì) íŒ¨í„´ ì°¾ê¸°
        match = re.search(r"(\d+(\.\d+)?)", text)
        if match:
            return float(match.group(1))
    except:
        pass
    return 0.0


# =========================================================
# [í•¨ìˆ˜ ìˆ˜ì •] ì¤„ë°”ê¿ˆ ë¬´ì‹œí•˜ê³  ì „ì²´ì—ì„œ ìˆœë„ ì°¾ê¸°
# =========================================================
def extract_purity(text):
    """ 
    ì¤„ë°”ê¿ˆì´ í¬í•¨ëœ ê¸´ í…ìŠ¤íŠ¸ì—ì„œ ìˆœë„(24K, 18K, Au995 ë“±)ë¥¼ ì°¾ì•„ëƒ„ 
    """
    if not text:
        return "UNKNOWN"

    # 1. ë¶„ì„í•˜ê¸° ì¢‹ê²Œ ëŒ€ë¬¸ìë¡œ ë³€í™˜
    # (ì¤„ë°”ê¿ˆ ë¬¸ìëŠ” ë†”ë‘¬ë„ re.searchê°€ ì•Œì•„ì„œ ê±´ë„ˆë›°ë©° ì°¾ìŒ)
    target_text = text.upper()
    
    # 2. ìš°ì„ ìˆœìœ„ë³„ ê²€ì‚¬ (24K > 18K > 14K)
    
    # [24K / ìˆœê¸ˆ] Au999, Au995, 999, 24K, ìˆœê¸ˆ
    if re.search(r'(24K|ìˆœê¸ˆ|AU99|999|995)', target_text):
        return "24K"
    
    # [18K] Au750, 750, 18K
    if re.search(r'(18K|AU750|750)', target_text):
        return "18K"
    
    # [14K] Au585, 585, 14K
    if re.search(r'(14K|AU585|585)', target_text):
        return "14K"
    
    # [ë°±ê¸ˆ/ì€]
    if re.search(r'(PT|PLATINUM|ë°±ê¸ˆ)', target_text):
        return "PLATINUM"
    if re.search(r'(AG|SILVER|ì€|ê·¸ë˜ë‰¼)', target_text):
        return "SILVER"

    return "UNKNOWN"

# =========================================================
# 3. ë©”ì¸ í¬ë¡¤ëŸ¬ ë¡œì§
# =========================================================
def run_scraper():
    print("=== ğŸ›¸ [Probe] ì •ì°° ë° ìƒì„¸ ì„±ë¶„ ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤ ===")
    
    options = webdriver.ChromeOptions()
    options.add_argument('--headless') # ë¸Œë¼ìš°ì € ì•ˆ ë„ìš°ë ¤ë©´ ì£¼ì„ í•´ì œ
    options.add_argument('window-size=1920x1080')
    
    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
    
    # ìˆ˜ì§‘í•  íƒ€ê²Ÿ ë¦¬ìŠ¤íŠ¸ (1ì°¨ ìˆ˜ì§‘ ì •ë³´)
    scraped_targets = []

    try:
        # --- [Phase 1] ë¦¬ìŠ¤íŠ¸ í˜ì´ì§€ì—ì„œ ëª©ë¡ í™•ë³´ ---
        url = "https://www.kapao.co.kr/ver2/p/item/item"
        driver.get(url)
        time.sleep(2)

        # 'ê·€ê¸ˆì†' ì¹´í…Œê³ ë¦¬ ì²´í¬ ë° ê²€ìƒ‰
        try:
            target_xpath = "//*[@id='cate-info']//label[contains(., 'ê·€ê¸ˆì†')]"
            checkbox = driver.find_element(By.XPATH, target_xpath)
            driver.execute_script("arguments[0].click();", checkbox)
            time.sleep(1)
            
            search_form = driver.find_element(By.ID, "frm_item_search")
            search_form.submit()
            print(">> ë¦¬ìŠ¤íŠ¸ ê°±ì‹  ì¤‘...")
            time.sleep(3) 
        except Exception as e:
            print(f"!! ê²€ìƒ‰ ì„¤ì • ì‹¤íŒ¨: {e}")
            return

        # ë¦¬ìŠ¤íŠ¸ ì•„ì´í…œ ê°€ì ¸ì˜¤ê¸°
        items = driver.find_elements(By.XPATH, "/html/body/div[4]/main/div[2]/div[5]/ul/li")
        print(f">> ë°œê²¬ëœ ë§¤ë¬¼: {len(items)}ê°œ (ìƒì„¸ ìˆ˜ì§‘ ëŒ€ê¸°ì¤‘)")

        # ë¦¬ìŠ¤íŠ¸ ë£¨í”„: URLê³¼ ê¸°ë³¸ ì •ë³´ë§Œ ë¹ ë¥´ê²Œ ì €ì¥
        for item in items:
            try:
                a_tag = item.find_element(By.XPATH, "./a")
                link = a_tag.get_attribute("href")
                
                # ì´ë¯¸ì§€
                try: img_src = item.find_element(By.XPATH, "./a/div[1]/div/img").get_attribute("src")
                except: img_src = ""

                # ë¦¬ìŠ¤íŠ¸ ìƒì˜ ìš”ì•½ í…ìŠ¤íŠ¸ íŒŒì‹±
                dl_tag = item.find_element(By.XPATH, "./a/div[2]/dl")
                raw_text = dl_tag.text 
                
                title = "ì œëª© ì—†ìŒ"
                price = 0
                location = "ë¯¸ë¶„ë¥˜"
                
                lines = raw_text.split('\n')
                for line in lines:
                    if "ë¬¼í’ˆëª…" in line: title = line.replace("ë¬¼í’ˆëª…", "").strip()
                    if "ê°ì •í‰ê°€ì•¡" in line or "ìµœì €ì…ì°°ê°€" in line: 
                        # ê°€ê²© ìˆ«ìë§Œ ì¶”ì¶œ
                        nums = re.findall(r'\d+', line.replace(",", ""))
                        if nums: price = int(nums[-1])
                    if "ë³´ê´€ì¥ì†Œ" in line: location = line.replace("ë³´ê´€ì¥ì†Œ", "").strip()

                scraped_targets.append({
                    "url": link,
                    "title": title,
                    "price": price,
                    "location": location,
                    "image_url": img_src,
                    "list_text": raw_text
                })
            except Exception as e:
                print(f"   âš ï¸ ë¦¬ìŠ¤íŠ¸ íŒŒì‹± ê±´ë„ˆëœ€: {e}")
                continue

        # --- [Phase 2] ìƒì„¸ í˜ì´ì§€ ìˆœíšŒ (ë°©ë¬¸íŒë§¤) ---
        print(f"\n>> ğŸ” ìƒì„¸ í˜ì´ì§€ ì§„ì… ì‹œì‘ ({len(scraped_targets)}ê°œ)")
        
        for idx, target in enumerate(scraped_targets):
            current_url = target['url']
            
            try:
                print(f"[{idx+1}/{len(scraped_targets)}] ì´ë™: {target['title'][:10]}...", end="")
                
                driver.get(current_url)
                time.sleep(random.uniform(1.5, 3.5)) # ëœë¤ íœ´ì‹

                # --- ë°ì´í„° ì¶”ì¶œ ---
                weight_g = 0.0
                full_description = target['list_text'] # ê¸°ë³¸ê°’
                purity_val = "UNKNOWN"

                # 1. ë¬´ê²Œ ì¶”ì¶œ
                try:
                    weight_element = driver.find_element(By.XPATH, "/html/body/div[4]/main/div[3]/div[1]/div[2]/dl[3]/dd/span")
                    weight_g = extract_weight(weight_element.text)
                    if weight_g > 0:
                        print(f" -> âš–ï¸ {weight_g}g", end="")
                except:
                    pass

                # 2. ìƒì„¸ ì„¤ëª… ë° ìˆœë„ ì¶”ì¶œ (â˜… í•µì‹¬ ìˆ˜ì • ë¶€ë¶„)
                # div ìœ„ì¹˜ê°€ 9ë²ˆì¼ ìˆ˜ë„, 13ë²ˆì¼ ìˆ˜ë„ ìˆìœ¼ë‹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ìˆœíšŒí•˜ë©° ì°¾ìŒ
                possible_xpaths = [
                    "/html/body/div[4]/main/div[3]/div[4]/div[1]/div[13]", # ë„¤ê°€ ìƒˆë¡œ ë°œê²¬í•œ ê³³
                    "/html/body/div[4]/main/div[3]/div[4]/div[1]/div[9]",  # ì•„ê¹Œ ë°œê²¬í•œ ê³³
                    "/html/body/div[4]/main/div[3]/div[4]/div[1]"          # ì „ì²´ ë°•ìŠ¤ (ìµœí›„ì˜ ìˆ˜ë‹¨)
                ]

                for xpath in possible_xpaths:
                    try:
                        element = driver.find_element(By.XPATH, xpath)
                        text = element.text.strip()
                        
                        # ë‚´ìš©ì´ ë¹„ì–´ìˆì§€ ì•Šìœ¼ë©´ ì´ê±¸ ìƒì„¸ ì„¤ëª…ìœ¼ë¡œ ì±„íƒ!
                        if text:
                            full_description = text
                            # ì „ì²´ í…ìŠ¤íŠ¸ ì•ˆì—ì„œ ìˆœë„ ê²€ìƒ‰ (ì¤„ë°”ê¿ˆ í¬í•¨)
                            purity_found = extract_purity(full_description)
                            
                            if purity_found != "UNKNOWN":
                                purity_val = purity_found
                            break # ì°¾ì•˜ìœ¼ë©´ ë£¨í”„ íƒˆì¶œ
                    except:
                        continue

                if purity_val != "UNKNOWN":
                    print(f" / ğŸ¥‡ {purity_val}", end="")

                # --- DB ì €ì¥ ---
                AuctionItem.objects.update_or_create(
                    url=current_url,
                    defaults={
                        'title': target['title'],
                        'price': target['price'],
                        'location': target['location'],
                        'image_url': target['image_url'],
                        
                        # [ì¤‘ìš”] ì „ì²´ ë‚´ìš©ì„ ë‹¤ ì €ì¥í•´ë‘  (ë‚˜ì¤‘ì— AIê°€ ë‹¤ì‹œ ë¶„ì„ ê°€ëŠ¥)
                        'description': full_description, 
                        'weight_g': weight_g,            
                        'purity': purity_val,            
                    }
                )
                print(" [ì €ì¥ì™„ë£Œ]")

            except Exception as e:
                print(f"\n   âš ï¸ ìƒì„¸ í˜ì´ì§€ ì—ëŸ¬ ({current_url}): {e}")
                continue
                
    except Exception as e:
        print(f"!! ì¹˜ëª…ì  ì—ëŸ¬ ë°œìƒ: {e}")
    
    finally:
        driver.quit()
        print("\n=== ğŸ ì •ì°° ì¢…ë£Œ ===")

if __name__ == "__main__":
    run_scraper()